{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 32, 'L': 3, 'LU_decomposed': True, 'actnorm_scale': 1.0, 'augment': True, 'batch_size': 64, 'cuda': True, 'dataroot': './', 'dataset': 'cifar10', 'download': False, 'epochs': 1500, 'eval_batch_size': 512, 'flow_coupling': 'affine', 'flow_permutation': 'invconv', 'fresh': True, 'hidden_channels': 512, 'learn_top': True, 'lr': 0.0005, 'max_grad_clip': 0, 'max_grad_norm': 0, 'n_init_batches': 8, 'n_workers': 6, 'output_dir': 'output/', 'saved_model': '', 'saved_optimizer': '', 'seed': 0, 'warmup_steps': 4000, 'y_condition': False, 'y_weight': 0.01}\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:05<00:00, 32134644.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/CIFAR10/cifar-10-python.tar.gz to data/CIFAR10\n",
      "Files already downloaded and verified\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data/SVHN/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182040794/182040794 [00:37<00:00, 4862744.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to data/SVHN/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64275384/64275384 [00:14<00:00, 4459422.60it/s]\n",
      "/Users/charumathibadrinath/Glow-PyTorch/modules.py:318: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2432.)\n",
      "  w_init = torch.qr(torch.randn(*w_shape))[0]\n",
      "/Users/charumathibadrinath/opt/miniconda3/lib/python3.9/site-packages/torch/functional.py:1822: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "LU, pivots = torch.lu(A, compute_pivots)\n",
      "should be replaced with\n",
      "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "and\n",
      "LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "should be replaced with\n",
      "LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2002.)\n",
      "  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb Cell 1\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m image_shape, num_classes, _, test_svhn \u001b[39m=\u001b[39m get_SVHN(hparams[\u001b[39m'\u001b[39m\u001b[39maugment\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mdataroot\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m model \u001b[39m=\u001b[39m Glow(image_shape, hparams[\u001b[39m'\u001b[39m\u001b[39mhidden_channels\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mK\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mactnorm_scale\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m              hparams[\u001b[39m'\u001b[39m\u001b[39mflow_permutation\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mflow_coupling\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39mLU_decomposed\u001b[39m\u001b[39m'\u001b[39m], num_classes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m              hparams[\u001b[39m'\u001b[39m\u001b[39mlearn_top\u001b[39m\u001b[39m'\u001b[39m], hparams[\u001b[39m'\u001b[39m\u001b[39my_condition\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(output_folder \u001b[39m+\u001b[39;49m model_name))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mset_actnorm_init()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charumathibadrinath/Glow-PyTorch/Do_deep_generative_models_know_what_they_dont_know.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1027\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m-> 1028\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1254\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1255\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1256\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1258\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1260\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:1193\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1193\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[1;32m   1194\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1195\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1196\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m typed_storage\n\u001b[1;32m   1197\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    380\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 381\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    382\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:274\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 274\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    275\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    276\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/serialization.py:258\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    255\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    259\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    260\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    261\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    262\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from datasets import get_CIFAR10, get_SVHN\n",
    "from model import Glow\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "output_folder = '/Users/charumathibadrinath/Downloads/glow/'\n",
    "model_name = 'glow_affine_coupling.pt'\n",
    "\n",
    "with open(output_folder + 'hparams.json') as json_file:  \n",
    "    hparams = json.load(json_file)\n",
    "    \n",
    "print(hparams)\n",
    "\n",
    "image_shape, num_classes, _, test_cifar = get_CIFAR10(hparams['augment'], hparams['dataroot'], True)\n",
    "image_shape, num_classes, _, test_svhn = get_SVHN(hparams['augment'], hparams['dataroot'], True)\n",
    "\n",
    "model = Glow(image_shape, hparams['hidden_channels'], hparams['K'], hparams['L'], hparams['actnorm_scale'],\n",
    "             hparams['flow_permutation'], hparams['flow_coupling'], hparams['LU_decomposed'], num_classes,\n",
    "             hparams['learn_top'], hparams['y_condition'])\n",
    "\n",
    "model.load_state_dict(torch.load(output_folder + model_name))\n",
    "model.set_actnorm_init()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nll(dataset, model):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=512, num_workers=6)\n",
    "    \n",
    "    nlls = []\n",
    "    for x,y in dataloader:\n",
    "        x = x.to(device)\n",
    "        \n",
    "        if hparams['y_condition']:\n",
    "            y = y.to(device)\n",
    "        else:\n",
    "            y = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, nll, _ = model(x, y_onehot=y)\n",
    "            nlls.append(nll)\n",
    "        \n",
    "    return torch.cat(nlls).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar_nll = compute_nll(test_cifar, model)\n",
    "svhn_nll = compute_nll(test_svhn, model)\n",
    "\n",
    "print(\"CIFAR NLL\", torch.mean(cifar_nll))\n",
    "print(\"SVHN NLL\", torch.mean(svhn_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Histogram Glow - trained on CIFAR10\")\n",
    "plt.xlabel(\"Negative bits per dimension\")\n",
    "plt.hist(-svhn_nll.numpy(), label=\"SVHN\", density=True, bins=30)\n",
    "plt.hist(-cifar_nll.numpy(), label=\"CIFAR10\", density=True, bins=50)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.savefig(\"images/histogram_glow_cifar_svhn.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
